# 前馈神经网络

**神经网络的3个主要的特性:**

1. 信息表示是分布式的( 非局部的 );

2. 记忆和知识是存储在单元之间的连接上;

3. 通过逐渐改变单元之间的连接强度来学习新的知识.

## 常见的激活函数及其性质:

![](/home/sxz/The%20Final%20Battle%20of%20the%20Semester/Machine_Learning/2024-06-04_16-03.png)

## 人工神经网络的三个方面:

1. **神经元的激活规则**
   
   * 主要是指神经元输入到输出之间的映射关系，一般为非线性函数。

2. **网络拓扑结构**
   
   * 不同神经元之间的连接关系。

3. **学习算法**
   
   * 通过训练数据来学习神经网络的参数。

## 前馈神经网络的基本特点

1. 各神经元分别属于不同的层,层内无连接.

2. 相邻两层之间的神经元全部两两连接

3. 整个网络中无反馈, 信号从输入层向输出层单向传播, 可用一个有向无环图表示.
   
   ![2024-06-04_16-13.png](/home/sxz/The%20Final%20Battle%20of%20the%20Semester/Machine_Learning/2024-06-04_16-13.png)

## 计算梯度(求导链式法则)

* 自动微分: 链式法则来自动计算一个复合函数的梯度

* 反向传播算法: 前馈神经网络的计算过程
  
  * 前向计算每一层的状态激活值,直到最后一层
  
  * 反向计算每一层的参数的偏导数
  
  * 更新参数

## 静态计算图( tensorflow )

与动态计算图不同，静态计算图在模型训练或推理之前首先定义和优化，然后在执行时重复使用。

## 动态计算图

动态计算图在执行时即时构建和修改，而不是在运行之前预先定义和优化。灵活性好,性能低

## 深度学习的三个步骤

1. 定义网络

2. 损失函数

3. 优化

## 误差反向传播

**大体过程描述**: 首先通过正向传播算出预测值,再通过真实值算出误差. 此时的误差应该是关于各权重系数的函数, 因此通过链式法则跟新各权重:

$$
\omega^*_i=\omega_i-\eta\frac{\partial E}{\partial \omega_i}
$$
