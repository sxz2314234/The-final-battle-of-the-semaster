# 第六章: 循环神经网络

## RNN的概念

通过使用带自反馈的神经元, 能够处理任意长度的时序数据.

<img src="https://pic4.zhimg.com/v2-3884f344d71e92d70ec3c44d2795141f_r.jpg" title="" alt="" width="381">\

![](https://pic1.zhimg.com/v2-206db7ba9d32a80ff56b6cc988a62440_r.jpg)

## 应用到机器学习

* 序列到类别
  
  ![2024-06-07_14-26.png](/home/sxz/The%20Final%20Battle%20of%20the%20Semester/Machine_Learning/2024-06-07_14-26.png)

*  同步的序列到序列模式
  
  * ![](/home/sxz/The%20Final%20Battle%20of%20the%20Semester/Machine_Learning/2024-06-07_14-44.png)

* 异步的序列到序列模式
  
  * ![2024-06-07_14-49.png](/home/sxz/The%20Final%20Battle%20of%20the%20Semester/Machine_Learning/2024-06-07_14-49.png)
  
  

## RNN优化: 随时间反向传播算法BPTT

RNN具有时间维度，因此需要处理随时间传播的梯度。BPTT的核心思想是将RNN的展开图视为一个多层的前馈神经网络，然后应用标准的反向传播算法来计算梯度。

## 遇到的问题

**长程依赖问题 :** 由于梯度爆炸或消失问题, 实际上只能学习到短周期的依赖关系

## 解决措施:

* 循环边改为线性依赖关系:$h_t=h_{t-1}+g(x_t;\theta) $

* 增加非线性: $h_t=h_{t-1}+g(x_t,h_{t-1};\theta) $

## 长短期记忆神经网络（Long Short-Term Memory, LSTM ）

LSTM包含三个门控单元，分别是遗忘门（forget gate）、输入门（input gate）和输出门（output gate），以及一个用于更新细胞状态的“细胞状态更新”步骤。

**以下是LSTM的关键组成部分**

1. **细胞状态（Cell State）**：细胞状态是LSTM网络中的核心，它允许信息在长期时间跨度上流动。细胞状态类似于传送带，信息可以在上面流动而不受门控单元的影响。

2. **遗忘门（Forget Gate）**：遗忘门决定了在当前时间步，要从细胞状态中丢弃哪些信息。它接收前一个时间步的隐藏状态和当前时间步的输入，并输出一个在0到1之间的值，表示要保留的信息量。0表示完全遗忘，1表示完全保留。

3. **输入门（Input Gate）**：输入门决定了在当前时间步，要向细胞状态中添加哪些新信息。它也使用前一个时间步的隐藏状态和当前时间步的输入来生成一个在0到1之间的值，表示要更新的信息量。

4. **细胞状态更新**：细胞状态更新步骤使用遗忘门和输入门的输出来更新细胞状态。首先，通过遗忘门确定要丢弃的信息，然后使用输入门确定要添加的新信息。

5. **输出门（Output Gate）**：输出门决定了在当前时间步，要从更新后的细胞状态中输出多少信息给下一个时间步的隐藏状态。它也是根据前一个时间步的隐藏状态和当前时间步的输入来生成一个在0到1之间的值。

## 深层模型

堆叠循环神经网络, 双向循环神经网络

## 序列到序列

编码器, 解码器
